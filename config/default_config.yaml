# Global training parameters
training:
  num_epochs: 20
  batch_size: 64
  max_seq_len: 1024
  update_target_every: 5
  epsilon_start: 0.9
  epsilon_end: 0.1
  epsilon_decay: 0.95
  reward_agreement_threshold: 0.6

# Optimizer configuration
optimizer:
  learning_rate: 0.0001
  weight_decay: 0.00001

# Scheduler configuration
scheduler:
  step_size: 10
  decay_rate: 0.95

# PTM integration
integration:
  num_agents: 5
  action_dim: 1024

# Device
device: "cuda"  # or "cpu"

# Logging and checkpoints
logging:
  log_dir: "logs"
  checkpoint_dir: "checkpoints"
  verbose: true

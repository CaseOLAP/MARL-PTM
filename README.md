## ðŸ§¬ MARL-PTM: A Modular Multi-Agent Reinforcement Learning System for Predicting Post-Translational Modifications

**MARL-PTM** is a state-of-the-art multi-agent deep learning framework for predicting residue-specific post-translational modifications (PTMs) using six biological data modalities. Designed around a **Centralized Training, Decentralized Execution (CTDE)** paradigm, MARL-PTM simulates specialized biological reasoning through reinforcement-learned PTM agents.

---

## ðŸ”§ I. Full Architecture Overview

### ðŸ§© Agent Layers

| **Level**       | **Agent Name**    | **Function**                                                   |
| --------------- | ----------------- | -------------------------------------------------------------- |
| Data Agents (6) | `SequenceAgent`   | Encodes amino acid motifs and sequential dependencies          |
|                 | `StructureAgent`  | Learns from DSSP and 3D features (e.g., helix, sheet, coil)    |
|                 | `GraphAgent`      | Processes residue-residue contact graphs                       |
|                 | `NetworkAgent`    | Embeds pathway and interaction network context                 |
|                 | `ExpressionAgent` | Captures context-specific expression patterns                  |
|                 | `ProteoformAgent` | Encodes historical PTM sites and isoform variants              |
| Integration     | `IntegratorAgent` | Learns to fuse embeddings across modalities via attention      |
| PTM Agents (13) | `PTMAgent_k`      | Learns PTM-specific classifiers (e.g., phosphorylation, etc.)  |
| Aggregator      | `AggregatorAgent` | Resolves competition between PTM agents to finalize prediction |

---

```text
[ Protein_ID ]
     â†“
[ Data Loaders ] â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â†“            â†“            â†“            â†“            â†“            â†“            â†“
            [Seq Agent]   [Str Agent]  [Graph Agent]  [Expr Agent]  [Prot Agent]  [Net Agent]   ...
                   â†“            â†“            â†“            â†“            â†“            â†“
                   â””â”€â”€â”€â”€â”€â”€â†’ [Integrator Agent: Fuse 6 Ã— [L, D] â†’ H] â”€â”€â”€â”€â”€â”€â”€â”€â†’
                                                   â†“
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â†“             â†“               â†“
                            [PTM Agent 1]   ...   [PTM Agent 13]
                                    â†“             â†“
                                  PTM Scores [L] Ã— 13
                                    â†“
                           [Aggregator Agent: Argmax across PTMs]
                                    â†“
                      {residue: (PTM type, confidence score)}
```

## ðŸ” II. Training Methodology

### ðŸ— Centralized Training, Decentralized Execution (CTDE)

* **Training**: All agents access shared embeddings and optimize jointly.
* **Execution**: Each PTM agent independently predicts residue-level scores.
* **Communication**: Through vector embeddings; no direct messaging between agents.

### ðŸŽ¯ Reward Structure

| **Condition**                    | **Reward** |
| -------------------------------- | ---------- |
| âœ… Correct PTM and correct site   | +1.0       |
| âŒ Incorrect PTM (false positive) | -1.0       |
| ðŸ”„ Correct site, wrong PTM       | +0.5       |
| ðŸ§¬ Motif/Proteoform matched      | +0.25      |

Bonus rewards reflect biological plausibility even in ambiguous sites.

### ðŸ” Optimization

* Loss: `BCEWithLogitsLoss` + optional reward-shaping
* Optimizer: `Adam` with optional warmup + decay
* Strategy: Multi-agent shared gradients through integrator â†’ data agents

---

## ðŸ“ III. Codebase Overview

```
MARL-PTM/
â”‚
â”œâ”€â”€ data_loaders/          # Modality-specific tensor loaders
â”‚   â”œâ”€â”€ sequence_loader.py
â”‚   â”œâ”€â”€ structure_loader.py
â”‚   â”œâ”€â”€ graph_loader.py
â”‚   â”œâ”€â”€ expression_loader.py
â”‚   â”œâ”€â”€ proteoform_loader.py
â”‚   â””â”€â”€ network_loader.py
â”‚
â”œâ”€â”€ agents/                # Agent architectures and logic
â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”œâ”€â”€ sequence_agent.py
â”‚   â”œâ”€â”€ structure_agent.py
â”‚   â”œâ”€â”€ graph_agent.py
â”‚   â”œâ”€â”€ expression_agent.py
â”‚   â”œâ”€â”€ proteoform_agent.py
â”‚   â”œâ”€â”€ network_agent.py
â”‚   â”œâ”€â”€ integrator_agent.py
â”‚   â”œâ”€â”€ ptm_agent.py
â”‚   â””â”€â”€ aggregator_agent.py
â”‚
â”œâ”€â”€ training/              # Training orchestration
â”‚   â”œâ”€â”€ train_loop.py
â”‚   â”œâ”€â”€ replay_buffer.py
â”‚   â”œâ”€â”€ rewards.py
â”‚   â””â”€â”€ scheduler.py
â”‚
â”œâ”€â”€ configs/               # YAML configuration files
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ utils/                 # Logging, visualization, metrics
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ inference/             # Inference & PTM site prediction
â”‚   â””â”€â”€ predict_ptms.py
â”‚
â””â”€â”€ main.py                # Entry point for training
```

---

## ðŸ“¦ Installation

```bash
git clone https://github.com/yourusername/MARL-PTM.git
cd MARL-PTM
pip install -r requirements.txt
```

Optional: install `torch-geometric` with correct CUDA version via:
[https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)

---

## ðŸš€ Getting Started

To train your model on synthetic or real-world datasets:

```bash
python main.py
```

To predict PTMs for trained models:

```bash
python inference/predict_ptms.py
```

Modify `configs/config.yaml` to set paths, agents, and hyperparameters.

---

## ðŸ“Š Evaluation

Performance is measured per PTM using:

* Precision / Recall / F1-score
* ROC-AUC (optional)
* Top-k residue prediction accuracy

---

## ðŸ“š Citation

If you use MARL-PTM in your research, please cite:

> "MARL-PTM: A Multi-Agent Reinforcement Learning Framework for Predicting Post-Translational Modifications", \[Author names], 2025. bioRxiv (in preparation)

---

## ðŸ§  Contributions Welcome!

Weâ€™re happy to collaborate on:

* Additional PTM types (e.g., SUMOylation, ADP-ribosylation)
* Real-world PTM data integration
* New reward strategies or graph encoders

Feel free to fork the repo, open issues, or submit a pull request!

---

Would you like this converted to a `README.md` file or want badges (license, build, citation) added next?
